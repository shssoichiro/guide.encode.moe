
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Masking, Limiting, and Related Functions Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-image-captions/image-captions.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-term/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="../styles/website.css">
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="descaling.html" />
    
    
    <link rel="prev" href="scenefiltering.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Overview</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../CONTRIBUTING.html">
            
                <a href="../CONTRIBUTING.html">
            
                    
                    Contributing to the Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../overview/preface.html">
            
                <a href="../overview/preface.html">
            
                    
                    Preface
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../overview/roles.html">
            
                <a href="../overview/roles.html">
            
                    
                    Roles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../overview/requirements.html">
            
                <a href="../overview/requirements.html">
            
                    
                    Requirements
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Encoding</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="preparation.html">
            
                <a href="preparation.html">
            
                    
                    Preparations and Necessary Software
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="basics-and-workflow.html">
            
                <a href="basics-and-workflow.html">
            
                    
                    Basics and General Workflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="video-artifacts.html">
            
                <a href="video-artifacts.html">
            
                    
                    Recognizing Video Artifacts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="scenefiltering.html">
            
                <a href="scenefiltering.html">
            
                    
                    Scenefiltering
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="2.5" data-path="masking-limiting-etc.html">
            
                <a href="masking-limiting-etc.html">
            
                    
                    Masking, Limiting, and Related Functions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="descaling.html">
            
                <a href="descaling.html">
            
                    
                    Descaling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="resampling.html">
            
                <a href="resampling.html">
            
                    
                    Resampling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="video-encoding.html">
            
                <a href="video-encoding.html">
            
                    
                    Codecs
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Typesetting</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../typesetting/aegisub.html">
            
                <a href="../typesetting/aegisub.html">
            
                    
                    Aegisub and Other Tools
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Resources and References</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../archived-websites/bt601-vs-bt709.html">
            
                <a href="../archived-websites/bt601-vs-bt709.html">
            
                    
                    Colorspaces
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Legal</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="../impressum.html">
            
                <a href="../impressum.html">
            
                    
                    Impressum
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="../privacy-policy.html">
            
                <a href="../privacy-policy.html">
            
                    
                    Privacy Policy
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Masking, Limiting, and Related Functions</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="masking-limiting-and-related-functions"><a name="masking-limiting-and-related-functions" class="plugin-anchor" href="#masking-limiting-and-related-functions"><i class="fa fa-link" aria-hidden="true"></i></a>Masking, Limiting, and Related Functions</h1>
<p>There are filters
which change the video in various ways,
and then there are ways to change the filtering itself.
There are likely hundreds of different techniques at your disposal
for various situations,
using masks to protect details from smoothing filters,
blending two clips with different filtering applied,
and countless others&#x2014;many of which haven&apos;t been thought of yet.
This article will cover:</p>
<ul>
<li>Masking and Merging</li>
<li>Limiting</li>
<li>Reference clips</li>
<li>Expressions and Lookup Tables</li>
<li>Runtime functions</li>
<li>Prefiltering</li>
</ul>
<h2 id="masking"><a name="masking" class="plugin-anchor" href="#masking"><i class="fa fa-link" aria-hidden="true"></i></a>Masking</h2>
<p>Masking refers to a broad set of techniques used to merge multiple clips.
Usually one filtered clip is merged with a source clip
according to an overlay mask clip.
A mask clip specifies the weight for each individual pixel
according to which the two clips are merged;
see <a href="#stdmaskedmerge">MaskedMerge</a> for details.</p>
<p>In practice,
masks are usually used to protect details,
texture, and/or edges
from destructive filtering effects like smoothing;
this is accomplished
by masking the areas to protect,
e.g. with an edgemask,
and merging the filtered clip with the unfiltered clip
according to the mask,
such that the masked areas are taken from the unfiltered clip,
and the unmasked areas are taken from the filtered clip.
In effect,
this applies the filtering only to the unmasked areas of the clip,
leaving the masked details/edges intact.</p>
<p>Mask clips are usually grayscale,
i.e. they consist of only one plane and thus contain no color information.
In VapourSynth, such clips use the color family <code>GRAY</code>
and one of these formats:
<code>GRAY8</code> (8 bits integer),
<code>GRAY16</code> (16 bits integer),
or <code>GRAYS</code> (single precision floating point).</p>
<h4 id="stdmaskedmerge"><a name="stdmaskedmerge" class="plugin-anchor" href="#stdmaskedmerge"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/maskedmerge.html" target="_blank">std.MaskedMerge</a></h4>
<p>This is the main function for masking
that performs the actual merging.
It takes three clips as input:
two source clips and one mask clip.
The output will be a convex combination of the input clips,
where the weights are given by the brightness of the mask clip.
The following formula
describes these internals for each pixel:</p>
<pre><code class="lang-py"><span class="hljs-comment"># in 8 bpp, MAX_VALUE would be 255</span>
output = clipa * (MAX_VALUE - mask) + clipb * mask
</code></pre>
<p>In simpler terms:
for brighter areas in the mask,
the output will come from <code>clipb</code>,
and for the dark areas,
it&#x2019;ll come from <code>clipa</code>.
Grey areas result in an average of <code>clipa</code> and <code>clipb</code>.</p>
<p>If <code>premultiplied</code> is set to True,
the equation changes as follows:</p>
<pre><code class="lang-py">output = clipa * (MAX_VALUE - mask) + clipb
</code></pre>
<hr>
<h3 id="manipulating-masks"><a name="manipulating-masks" class="plugin-anchor" href="#manipulating-masks"><i class="fa fa-link" aria-hidden="true"></i></a>Manipulating Masks</h3>
<p>Building precise masks
that cover exactly what you want
is often rather tricky.
VapourSynth provides basic tools for manipulating masks
that can be used to bring them into the desired shape:</p>
<h4 id="stdminimumstdmaximum"><a name="stdminimumstdmaximum" class="plugin-anchor" href="#stdminimumstdmaximum"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/minimum_maximum.html" target="_blank">std.Minimum/std.Maximum</a></h4>
<p>The Minimum/Maximum operations replace each pixel
with the smallest/biggest value in its 3x3 neighbourhood.
The 3x3 neighbourhood of a pixel
are the 8 pixels directly adjacent to the pixel in question
plus the pixel itself.</p>
<figure id="fig2.5.1"><img src="images/3x3.png" alt="Illustration of the 3x3 neighborhood"><figcaption>Image 2.5.1 - Illustration of the 3x3 neighborhood</figcaption></figure>
<p>The Minimum/Maximum filters
look at the 3x3 neighbourhood of each pixel in the input image
and replace the corresponding pixel in the output image
with the brightest (Maximum) or darkest (Minimum) pixel in that neighbourhood.</p>
<p>Maximum generally expands/grows a mask
because all black pixels adjacent to white edges will be turned white,
whereas Minimum generally shrinks the mask
because all white pixels bordering on black ones will be turned black.</p>
<p>See the next section for usage examples.</p>
<p>Side note:
In general image processing,
these operations are known as <a href="https://en.wikipedia.org/wiki/Erosion_(morphology)" target="_blank">Erosion</a> (Minimum)
and <a href="https://en.wikipedia.org/wiki/Dilation_(morphology)" target="_blank">Dilation</a> (Maximum).
Maximum/Minimum actually implement only a specific case
where the <a href="https://en.wikipedia.org/wiki/Structuring_element" target="_blank">structuring element</a> is a 3x3 square.
The built-in <code>morpho</code> plug-in implements the more general case
in the functions <code>morpho.Erode</code> and <code>morpho.Dilate</code>
which allow finer control over the structuring element.
However, these functions are significantly slower than
<code>std.Minimum</code> and <code>std.Maximum</code>.</p>
<h4 id="stdinflatestddeflate"><a name="stdinflatestddeflate" class="plugin-anchor" href="#stdinflatestddeflate"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/deflate_inflate.html" target="_blank">std.Inflate/std.Deflate</a></h4>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd></p>
<h4 id="stdbinarize"><a name="stdbinarize" class="plugin-anchor" href="#stdbinarize"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/binarize.html" target="_blank">std.Binarize</a></h4>
<p>Split the luma/chroma values of any clip into one of two values,
according to a fixed threshold.
For instance,
binarize an edgemask to white when edge values are at or above 24,
and set values lower to 0:</p>
<pre><code class="lang-py">mask.std.Binarize(<span class="hljs-number">24</span>, v0=<span class="hljs-number">0</span>, v1=<span class="hljs-number">255</span>)
</code></pre>
<p>For methods of creating mask clips,
there are a few general categories&#x2026;</p>
<h3 id="line-masks"><a name="line-masks" class="plugin-anchor" href="#line-masks"><i class="fa fa-link" aria-hidden="true"></i></a>Line masks</h3>
<p>These are used for normal edge detection,
which is useful for processing edges or the area around them,
like anti-aliasing and deringing.
The traditional edge detection technique is
to apply one or more convolutions,
focused in different directions,
to create a clip containing what you might call a gradient vector map,
or more simply a clip which has brighter values in pixels
where the neighborhood dissimilarity is higher.
Some commonly used examples would be <strong>Prewitt</strong> (core),
<strong>Sobel</strong> (core),
and <strong>kirsch</strong> (kagefunc).</p>
<p>There are also some edge detection methods that use prefiltering
when generating the mask.
The most common of these would be <strong>TCanny</strong>,
which applies a Gaussian blur before creating a 1-pixel-thick Sobel mask.
The most noteworthy pre-processed edge mask would be kagefunc&apos;s
<strong>retinex_edgemask</strong> filter,
which at least with cartoons and anime,
is unmatched in its accuracy.
This is the mask to use if you want edge
masking with ALL of the edges and nothing BUT the edges.</p>
<p>Another edge mask worth mentioning is the mask in dehalohmod,
which is a black-lineart mask well-suited to dehalo masking.
Internally it uses a mask called a Camembert to generate a larger mask
and limits it to the area affected by a line-darkening script.
The main mask has no name and is simply dhhmask(mode=3).</p>
<p>For more information about edgemasks,
see <a href="https://kageru.moe/blog/article/edgemasks" target="_blank">kageru&apos;s blog post</a>.</p>
<p>The <strong>range mask</strong>
(or in masktools,
the &quot;min/max&quot; mask)
also fits into this category.
It is a very simple masking method that
returns a clip made up of the maximum value of a range of neighboring pixels
minus the minimum value of the range,
as so:</p>
<pre><code class="lang-py">clipmax = core.std.Maximum(clip)
clipmin = core.std.Minimum(clip)
minmax = core.std.Expr([clipmax, clipmin], <span class="hljs-string">&apos;x y -&apos;</span>)
</code></pre>
<p>The most common use of this mask is within GradFun3.
In theory,
the neighborhood variance technique is the perfect fit for a debanding mask.
Banding is the result of 8 bit color limits,
so we mask any pixel with a neighbor higher or lower than one 8 bit color step,
thus masking everything except potential banding.
But alas,
grain induces false positives
and legitimate details within a single color step are smoothed out,
therefore debanding will forever be a balancing act between
detail loss and residual artifacts.</p>
<h4 id="example-build-a-simple-dehalo-mask"><a name="example-build-a-simple-dehalo-mask" class="plugin-anchor" href="#example-build-a-simple-dehalo-mask"><i class="fa fa-link" aria-hidden="true"></i></a>Example: Build a simple dehalo mask</h4>
<p>Suppose you want to remove these halos:</p>
<figure id="fig2.5.2"><img src="images/halos.png" alt="Screenshot of the source."><figcaption>Image 2.5.2 - Screenshot of the source.</figcaption></figure>
<figure id="fig2.5.3"><img src="images/src0.png" alt="Point-enlargement of the halo area."><figcaption>Image 2.5.3 - Point-enlargement of the halo area.</figcaption></figure>
<p>(Note that the images shown in your browser are likely resized poorly;
you can view them at full size in <a href="https://slowpics.org/comparison/96cbeca4-b4be-4dfc-82b1-631bbc85cdb0" target="_blank">this comparison</a>.)</p>
<p>Fortunately, there is a well-established script that does just that:
<a href="https://github.com/HomeOfVapourSynthEvolution/havsfunc/blob/8b2cd62a20faf0b410c742c95e7c7848894628d4/havsfunc.py#L370" target="_blank">DeHalo_alpha</a>.</p>
<p>However, we must be cautious in applying that filter,
since, while removing halos reliably,
it&#x2019;s extremly destructive to the lineart as well.
Therefore we must use a <strong>dehalo mask</strong>
to protect the lineart and limit the filtering to halos.</p>
<p>A dehalo mask aims to cover the halos
but exclude the lines themselves,
so that the lineart won&#x2019;t be blurred or dimmed.
In order to do that,
we first need to generate an edgemask.
In this example,
we&#x2019;ll use the built-in Sobel function.
After generating the edge mask, we extract the luma plane:</p>
<pre><code class="lang-py">mask = core.std.Sobel(src, <span class="hljs-number">0</span>)
luma = core.std.ShufflePlanes(mask, <span class="hljs-number">0</span>, colorfamily=vs.GRAY)
</code></pre>
<figure id="fig2.5.4"><img src="images/luma0.png" alt="luma"><figcaption>Image 2.5.4 - luma</figcaption></figure>
<p>Next, we expand the mask twice, so that it covers the halos.
<code>vsutil.iterate</code> is a <a href="https://github.com/Irrational-Encoding-Wizardry/vsutil/blob/c0206e2b68357fcbcfbcb47fafec70cce8391786/vsutil.py#L64" target="_blank">function in vsutil</a>
which applies the specified filter a specified number of times
to a clip&#x2014;in this case it runs <code>std.Maximum</code> 2 times.</p>
<pre><code class="lang-py">mask_outer = vsutil.iterate(luma, core.std.Maximum, <span class="hljs-number">2</span>)
</code></pre>
<figure id="fig2.5.5"><img src="images/mask_outer0.png" alt="mask_outer"><figcaption>Image 2.5.5 - mask_outer</figcaption></figure>
<p>Now we shrink the expanded clip back
to cover only the lineart.
Applying <code>std.Minimum</code> twice
would shrink it back to the edge mask&#x2019;s original size,
but since the edge mask covers part of the halos too,
we need to erode it a little further.</p>
<p>The reason we use <code>mask_outer</code> as the basis and shrink it thrice,
instead of using <code>mask</code> and shrinking it once,
which would result in a similar outline,
is that this way,
small adjacent lines with gaps in them
(i.e. areas of fine texture or details),
such as the man&#x2019;s eyes in this example,
are covered up completely,
preventing detail loss.</p>
<pre><code class="lang-py">mask_inner = vsutil.iterate(mask_outer, core.std.Minimum, <span class="hljs-number">3</span>)
</code></pre>
<figure id="fig2.5.6"><img src="images/mask_inner0.png" alt="mask_inner"><figcaption>Image 2.5.6 - mask_inner</figcaption></figure>
<p>Now we substract the outer mask covering the halos
and the lineart from the inner mask covering only the lineart.
This yields a mask covering only the halos,
which is what we originally wanted:</p>
<pre><code class="lang-py">halos = core.std.Expr([mask_outer, mask_inner], <span class="hljs-string">&apos;x y -&apos;</span>)
</code></pre>
<figure id="fig2.5.7"><img src="images/halos0.png" alt="halos"><figcaption>Image 2.5.7 - halos</figcaption></figure>
<p>Next, we do the actual dehaloing:</p>
<pre><code class="lang-py">dehalo = hf.DeHalo_alpha(src)
</code></pre>
<figure id="fig2.5.8"><img src="images/dh0.png" alt="dehalo"><figcaption>Image 2.5.8 - dehalo</figcaption></figure>
<p>Lastly, we use MaskedMerge to merge only the filtered halos
into the source clip,
leaving the lineart mostly untouched:</p>
<pre><code class="lang-py">masked_dehalo = core.std.MaskedMerge(src, dehalo, halos)
</code></pre>
<figure id="fig2.5.9"><img src="images/dehalod0.png" alt="masked_dehalo"><figcaption>Image 2.5.9 - masked_dehalo</figcaption></figure>
<hr>
<h3 id="diff-masks"><a name="diff-masks" class="plugin-anchor" href="#diff-masks"><i class="fa fa-link" aria-hidden="true"></i></a>Diff masks</h3>
<p>A diff(erence) mask is any mask clip
generated using the variance of two clips.
There are many different ways to use this type of mask:
limiting a difference to a threshold,
processing a filtered difference itself,
or smoothing &#x2192;
processing the clean clip &#x2192;
overlaying the original grain.
They can also be used in conjunction with
line masks,
for example:
kagefunc&apos;s hardsubmask uses a special edge mask with a diff mask,
and uses core.misc.Hysteresis to grow the line mask into diff mask.</p>
<h4 id="example-create-a-descale-mask-for-white-non-fading-credits-with-extra-protection-for-lines-16-bit-input"><a name="example-create-a-descale-mask-for-white-non-fading-credits-with-extra-protection-for-lines-16-bit-input" class="plugin-anchor" href="#example-create-a-descale-mask-for-white-non-fading-credits-with-extra-protection-for-lines-16-bit-input"><i class="fa fa-link" aria-hidden="true"></i></a>Example: Create a descale mask for white non-fading credits with extra protection for lines (16 bit input)</h4>
<pre><code class="lang-py">src16 = kgf.getY(last)
src32 = fvf.Depth(src16, <span class="hljs-number">32</span>)

standard_scale = core.resize.Spline36(last, <span class="hljs-number">1280</span>, <span class="hljs-number">720</span>, format=vs.YUV444P16, resample_filter_uv=<span class="hljs-string">&apos;spline16&apos;</span>)

inverse_scale = core.descale.Debicubic(src32, <span class="hljs-number">1280</span>, <span class="hljs-number">720</span>)
inverse_scale = fvf.Depth(inverse_scale, <span class="hljs-number">16</span>)

<span class="hljs-comment">#absolute error of descaling</span>
error = core.resize.Bicubic(inverse_scale, <span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>)
error = core.std.Expr([src, error], <span class="hljs-string">&apos;x y - abs&apos;</span>)

<span class="hljs-comment">#create a light error mask to protect smaller spots against halos aliasing and rings</span>
error_light = core.std.Maximum(error, coordinates=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>])
error_light = core.std.Expr(error_light, <span class="hljs-string">&apos;65535 x 1000 / /&apos;</span>)
error_light = core.resize.Spline36(error_light, <span class="hljs-number">1280</span>, <span class="hljs-number">720</span>)

<span class="hljs-comment">#create large error mask for credits, limiting the area to white spots</span>
<span class="hljs-comment">#masks are always full-range, so manually set fulls/fulld to True or range_in/range to 1 when changing bitdepth</span>
credits = core.std.Expr([src16, error], <span class="hljs-string">&apos;x 55800 &amp;gt; y 2500 &amp;gt; and 255 0 ?&apos;</span>, vs.GRAY8)
credits = core.resize.Bilinear(credits, <span class="hljs-number">1280</span>, <span class="hljs-number">720</span>)
credits = core.std.Maximum(credits).std.Inflate().std.Inflate()
credits = fvf.Depth(credits, <span class="hljs-number">16</span>, range_in=<span class="hljs-number">1</span>, range=<span class="hljs-number">1</span>)

descale_mask = core.std.Expr([error_light, credits], <span class="hljs-string">&apos;x y -&apos;</span>)

output = kgf.getY(standard_scale).std.MaskedMerge(inverse_scale, descale_mask)
output = muvf.MergeChroma(output, standard_scale)
</code></pre>
<h2 id="single-and-multi-clip-adjustments-with-stdexpr-and-friends"><a name="single-and-multi-clip-adjustments-with-stdexpr-and-friends" class="plugin-anchor" href="#single-and-multi-clip-adjustments-with-stdexpr-and-friends"><i class="fa fa-link" aria-hidden="true"></i></a>Single and multi-clip adjustments with std.Expr and friends</h2>
<p>Vapoursynth&apos;s core contains many such filters,
which can manipulate one to three different clips according to a math function.
Most, if not all,
can be done (though possibly slower) using std.Expr,
which will be
covered at the end of this
sub-section.</p>
<h4 id="stdmakediff-and-stdmergediff"><a name="stdmakediff-and-stdmergediff" class="plugin-anchor" href="#stdmakediff-and-stdmergediff"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/makediff.html" target="_blank">std.MakeDiff</a> and <a href="http://www.vapoursynth.com/doc/functions/mergediff.html" target="_blank">std.MergeDiff</a></h4>
<p>Subtract or add the difference of two clips, respectively.
These filters are peculiar in that they work differently in
integer and float formats,
so for more complex filtering
float is recommended whenever possible.
In 8 bit integer format where neutral luminance (gray) is 128,
the function is <code>clip1 - clip2 + 128</code> for MakeDiff
and <code>clip1 + clip2 - 128</code> for MergeDiff,
so pixels with no change will be gray.</p>
<p>The same is true of 16 bit and 32768.
The float version is simply <code>clip1 - clip2</code> so in 32 bit
the difference is defined normally,
negative for dark differences,
positive for bright differences,
and null differences are zero.</p>
<p>Since overflowing values are clipped to 0 and 255,
changes greater than 128 will be clipped as well.
This can be worked around by re-defining the input clip as so:</p>
<pre><code class="lang-py">smooth = core.bilateral.Bilateral(src, sigmaS=<span class="hljs-number">6.4</span>, sigmaR=<span class="hljs-number">0.009</span>)
noise = core.std.MakeDiff(src, smooth) <span class="hljs-comment"># subtract filtered clip from source leaving the filtered difference</span>
smooth = core.std.MakeDiff(src, noise) <span class="hljs-comment"># subtract diff clip to prevent clipping (doesn&apos;t apply to 32 bit)</span>
</code></pre>
<h4 id="stdmerge"><a name="stdmerge" class="plugin-anchor" href="#stdmerge"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/merge.html" target="_blank">std.Merge</a></h4>
<p>This function is similar to <a href="#stdmaskedmerge">MaskedMerge</a>,
the main difference being
that a constant weight is supplied
instead of a mask clip to read the weight from for each pixel.
The formula is thus just as simple:</p>
<pre><code class="lang-py">output = clipa * (MAX_VALUE - weight) + clipb * weight
</code></pre>
<p>It can be used to perform
a weighted average of two clips or planes.</p>
<h4 id="stdexpr"><a name="stdexpr" class="plugin-anchor" href="#stdexpr"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/expr.html" target="_blank">std.Expr</a></h4>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd></p>
<h4 id="stdlut-and-stdlut2"><a name="stdlut-and-stdlut2" class="plugin-anchor" href="#stdlut-and-stdlut2"><i class="fa fa-link" aria-hidden="true"></i></a><a href="http://www.vapoursynth.com/doc/functions/lut.html" target="_blank">std.Lut</a> and <a href="http://www.vapoursynth.com/doc/functions/lut2.html" target="_blank">std.Lut2</a></h4>
<p>May be slightly faster than Expr in some cases,
otherwise they can&apos;t really do anything that Expr can&apos;t.
You can substitute a normal Python function for the RPN expression, though,
so you may still find it easier.
See link for usage information.</p>
<h2 id="limiting"><a name="limiting" class="plugin-anchor" href="#limiting"><i class="fa fa-link" aria-hidden="true"></i></a>Limiting</h2>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd></p>
<h2 id="referencing"><a name="referencing" class="plugin-anchor" href="#referencing"><i class="fa fa-link" aria-hidden="true"></i></a>Referencing</h2>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd> - probably just merge with &quot;Limiting&quot;</p>
<h2 id="runtime-filtering-with-frameeval"><a name="runtime-filtering-with-frameeval" class="plugin-anchor" href="#runtime-filtering-with-frameeval"><i class="fa fa-link" aria-hidden="true"></i></a>Runtime filtering with FrameEval</h2>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd></p>
<h4 id="example-strong-smoothing-on-scene-changes-ie-for-mpeg-2-transport-streams"><a name="example-strong-smoothing-on-scene-changes-ie-for-mpeg-2-transport-streams" class="plugin-anchor" href="#example-strong-smoothing-on-scene-changes-ie-for-mpeg-2-transport-streams"><i class="fa fa-link" aria-hidden="true"></i></a>Example: Strong smoothing on scene changes (i.e. for MPEG-2 transport streams)</h4>
<pre><code class="lang-py"><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial

src = core.d2v.Source()
src = ivtc(src)
src = haf.Deblock_QED(src)

ref = core.rgvs.RemoveGrain(src, <span class="hljs-number">2</span>)

<span class="hljs-comment"># xvid analysis is better in lower resolutions</span>
first = core.resize.Bilinear(ref, <span class="hljs-number">640</span>, <span class="hljs-number">360</span>).wwxd.WWXD()
<span class="hljs-comment"># shift by one frame</span>
last = core.std.DuplicateFrames(first, src.num_frames - <span class="hljs-number">1</span>).std.DeleteFrames(<span class="hljs-number">0</span>)

<span class="hljs-comment"># copy prop to last frame of previous scene</span>
propclip = core.std.ModifyFrame(first, clips=[first, last], selector=shiftback)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shiftback</span><span class="hljs-params">(n, f)</span>:</span>
    both = f[<span class="hljs-number">0</span>].copy()
    <span class="hljs-keyword">if</span> f[<span class="hljs-number">1</span>].props.SceneChange == <span class="hljs-number">1</span>:
        both.props.SceneChange = <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> both

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">scsmooth</span><span class="hljs-params">(n, f, clip, ref)</span>:</span>
    <span class="hljs-keyword">if</span> f.props.SceneChange == <span class="hljs-number">1</span>:
        clip = core.dfttest.DFTTest(ref, tbsize=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> clip

out = core.std.FrameEval(src, partial(scsmooth, clip=src, ref=ref), prop_src=propclip)
</code></pre>
<h2 id="prefilters"><a name="prefilters" class="plugin-anchor" href="#prefilters"><i class="fa fa-link" aria-hidden="true"></i></a>Prefilters</h2>
<p><kbd> TODO <a href="https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/encoding/masking-limiting-etc.md" target="_blank"><i class="fa fa-edit"></i></a></kbd></p>
<h4 id="example-deband-a-grainy-clip-with-f3kdb-16-bit-input"><a name="example-deband-a-grainy-clip-with-f3kdb-16-bit-input" class="plugin-anchor" href="#example-deband-a-grainy-clip-with-f3kdb-16-bit-input"><i class="fa fa-link" aria-hidden="true"></i></a>Example: Deband a grainy clip with f3kdb (16 bit input)</h4>
<pre><code class="lang-py">src16 = last
src32 = fvf.Depth(last, <span class="hljs-number">32</span>)

<span class="hljs-comment"># I really need to finish zzfunc.py :&amp;lt;</span>
minmax = zz.rangemask(src16, rad=<span class="hljs-number">1</span>, radc=<span class="hljs-number">0</span>)

<span class="hljs-comment">#8-16 bit MakeDiff and MergeDiff are limited to 50% of full-range, so float is used here</span>
clean = core.std.Convolution(src32, [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]).std.Convolution([<span class="hljs-number">1</span>]*<span class="hljs-number">9</span>, planes=[<span class="hljs-number">0</span>])
grain = core.std.Expr([src32, clean32], <span class="hljs-string">&apos;x y - 0.5 +&apos;</span>)

clean = fvf.Depth(clean, <span class="hljs-number">16</span>)
deband =core.f3kdb.Deband(clean, <span class="hljs-number">16</span>, <span class="hljs-number">40</span>, <span class="hljs-number">40</span>, <span class="hljs-number">40</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, keep_tv_range=<span class="hljs-keyword">True</span>, output_depth=<span class="hljs-number">16</span>)

<span class="hljs-comment">#limit the debanding: f3kdb becomes very strong on the smoothed clip (or rather, becomes more efficient)</span>
<span class="hljs-comment">#adapt strength according to a neighborhood-similarity mask, steadily decreasing strength in more detailed areas</span>
limited = zz.AdaptiveLimitFilter(deband, clean, mask=minmax, thr1=<span class="hljs-number">0.3</span>, thr2=<span class="hljs-number">0.0</span>, mthr1=<span class="hljs-number">400</span>, mthr2=<span class="hljs-number">700</span>, thrc=<span class="hljs-number">0.25</span>)

output = fvf.Depth(limited, <span class="hljs-number">32</span>).std.MergeDiff(grain)
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="scenefiltering.html" class="navigation navigation-prev " aria-label="Previous page: Scenefiltering">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="descaling.html" class="navigation navigation-next " aria-label="Next page: Descaling">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Masking, Limiting, and Related Functions","level":"2.5","depth":1,"next":{"title":"Descaling","level":"2.6","depth":1,"path":"encoding/descaling.md","ref":"encoding/descaling.md","articles":[]},"previous":{"title":"Scenefiltering","level":"2.4","depth":1,"path":"encoding/scenefiltering.md","ref":"encoding/scenefiltering.md","articles":[]},"dir":"ltr"},"config":{"plugin_comments":{"anchors":"adds anchors (and links) to headings","code":"adds line numbers and copy buttons","edit-link":"link to edit page on github in top bar","image-captions":"turns images into figures","term":"{% term %} blocks with different highlighting and copy buttons per command, not whole output"},"plugins":["anchors","code","edit-link","image-captions","term"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"search":{},"term":{"copyButtons":true,"fade":false,"lineStyles":true,"prompt":"(?<prompt>[^\\$^#^:]*)(?<pathsep>:?)(?<path>[^\\$^#]*?)(?<delimiter>[\\$#] )(?<command>.*)$","style":"default"},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"edit-link":{"label":"Edit This Page","base":"https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{},"image-captions":{"caption":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","variable_name":"_pictures"}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{"_pictures":[{"backlink":"overview/roles.html#fig1.4.1","level":"1.4","list_caption":"Figure: [DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","alt":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","nro":1,"url":"images/cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","attributes":{},"skip":false,"key":"1.4.1"},{"backlink":"overview/roles.html#fig1.4.2","level":"1.4","list_caption":"Figure: [DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","alt":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","nro":2,"url":"images/cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","attributes":{},"skip":false,"key":"1.4.2"},{"backlink":"encoding/preparation.html#fig2.1.1","level":"2.1","list_caption":"Figure: The main window of VSEdit.","alt":"The main window of VSEdit.","nro":3,"url":"images/cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"The main window of VSEdit.","attributes":{},"skip":false,"key":"2.1.1"},{"backlink":"encoding/preparation.html#fig2.1.2","level":"2.1","list_caption":"Figure: A Jupyter Notebook.","alt":"A Jupyter Notebook.","nro":4,"url":"images/cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"A Jupyter Notebook.","attributes":{},"skip":false,"key":"2.1.2"},{"backlink":"encoding/preparation.html#fig2.1.3","level":"2.1","list_caption":"Figure: VS Multi-Viewerâs editing window.","alt":"VS Multi-Viewerâs editing window.","nro":5,"url":"images/VS-Multi-Viewer_Preview.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"VS Multi-Viewerâs editing window.","attributes":{},"skip":false,"key":"2.1.3"},{"backlink":"encoding/preparation.html#fig2.1.4","level":"2.1","list_caption":"Figure: VS Multi-Viewerâs preview window.","alt":"VS Multi-Viewerâs preview window.","nro":6,"url":"images/VS-Multi-Viewer_Editor.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"VS Multi-Viewerâs preview window.","attributes":{},"skip":false,"key":"2.1.4"},{"backlink":"encoding/video-artifacts.html#fig2.3.1","level":"2.3","list_caption":"Figure: Rakudai-Kishi-no-Cavalry-ep.01.png","alt":"Rakudai-Kishi-no-Cavalry-ep.01.png","nro":7,"url":"images/3cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Rakudai-Kishi-no-Cavalry-ep.01.png","attributes":{},"skip":false,"key":"2.3.1"},{"backlink":"encoding/video-artifacts.html#fig2.3.2","level":"2.3","list_caption":"Figure: Have I been staring at my monitor for too long?","alt":"Have I been staring at my monitor for too long?","nro":8,"url":"images/3cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Have I been staring at my monitor for too long?","attributes":{},"skip":false,"key":"2.3.2"},{"backlink":"encoding/video-artifacts.html#fig2.3.3","level":"2.3","list_caption":"Figure: notevenonce.jpg","alt":"notevenonce.jpg","nro":9,"url":"images/3cnvimage102.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"notevenonce.jpg","attributes":{},"skip":false,"key":"2.3.3"},{"backlink":"encoding/video-artifacts.html#fig2.3.4","level":"2.3","list_caption":"Figure: Blocky Compression","alt":"Blocky Compression","nro":10,"url":"images/blocky2.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Blocky Compression","attributes":{},"skip":false,"key":"2.3.4"},{"backlink":"encoding/video-artifacts.html#fig2.3.5","level":"2.3","list_caption":"Figure: Blocky Exaggeration","alt":"Blocky Exaggeration","nro":11,"url":"images/blocky1.jpg","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Blocky Exaggeration","attributes":{},"skip":false,"key":"2.3.5"},{"backlink":"encoding/video-artifacts.html#fig2.3.6","level":"2.3","list_caption":"Figure: Example image for banding","alt":"Example image for banding","nro":12,"url":"images/banding.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example image for banding","attributes":{},"skip":false,"key":"2.3.6"},{"backlink":"encoding/video-artifacts.html#fig2.3.7","level":"2.3","list_caption":"Figure: Mosquito Noise","alt":"Mosquito Noise","nro":13,"url":"images/mosquito1.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Mosquito Noise","attributes":{},"skip":false,"key":"2.3.7"},{"backlink":"encoding/video-artifacts.html#fig2.3.8","level":"2.3","list_caption":"Figure: field-noise.jpg","alt":"field-noise.jpg","nro":14,"url":"images/3cnvimage103.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"field-noise.jpg","attributes":{},"skip":false,"key":"2.3.8"},{"backlink":"encoding/video-artifacts.html#fig2.3.9","level":"2.3","list_caption":"Figure: Example of underflow (click for comparison)","alt":"Example of underflow (click for comparison)","nro":15,"url":"images/underflow.jpg","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example of underflow (click for comparison)","attributes":{},"skip":false,"key":"2.3.9"},{"backlink":"encoding/video-artifacts.html#fig2.3.10","level":"2.3","list_caption":"Figure: Example of overflow (click for comparison)","alt":"Example of overflow (click for comparison)","nro":16,"url":"images/overflow.jpg","index":10,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example of overflow (click for comparison)","attributes":{},"skip":false,"key":"2.3.10"},{"backlink":"encoding/video-artifacts.html#fig2.3.11","level":"2.3","list_caption":"Figure: When you see a histogram like this, increase precision.","alt":"When you see a histogram like this, increase precision.","nro":17,"url":"images/overflow_notice.jpg","index":11,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"When you see a histogram like this, increase precision.","attributes":{},"skip":false,"key":"2.3.11"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.1","level":"2.5","list_caption":"Figure: Illustration of the 3x3 neighborhood","alt":"Illustration of the 3x3 neighborhood","nro":18,"url":"images/3x3.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Illustration of the 3x3 neighborhood","attributes":{},"skip":false,"key":"2.5.1"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.2","level":"2.5","list_caption":"Figure: Screenshot of the source.","alt":"Screenshot of the source.","nro":19,"url":"images/halos.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Screenshot of the source.","attributes":{},"skip":false,"key":"2.5.2"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.3","level":"2.5","list_caption":"Figure: Point-enlargement of the halo area.","alt":"Point-enlargement of the halo area.","nro":20,"url":"images/src0.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Point-enlargement of the halo area.","attributes":{},"skip":false,"key":"2.5.3"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.4","level":"2.5","list_caption":"Figure: luma","alt":"luma","nro":21,"url":"images/luma0.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"luma","attributes":{},"skip":false,"key":"2.5.4"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.5","level":"2.5","list_caption":"Figure: mask_outer","alt":"mask_outer","nro":22,"url":"images/mask_outer0.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"mask_outer","attributes":{},"skip":false,"key":"2.5.5"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.6","level":"2.5","list_caption":"Figure: mask_inner","alt":"mask_inner","nro":23,"url":"images/mask_inner0.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"mask_inner","attributes":{},"skip":false,"key":"2.5.6"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.7","level":"2.5","list_caption":"Figure: halos","alt":"halos","nro":24,"url":"images/halos0.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"halos","attributes":{},"skip":false,"key":"2.5.7"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.8","level":"2.5","list_caption":"Figure: dehalo","alt":"dehalo","nro":25,"url":"images/dh0.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"dehalo","attributes":{},"skip":false,"key":"2.5.8"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.9","level":"2.5","list_caption":"Figure: masked_dehalo","alt":"masked_dehalo","nro":26,"url":"images/dehalod0.png","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"masked_dehalo","attributes":{},"skip":false,"key":"2.5.9"},{"backlink":"encoding/descaling.html#fig2.6.1","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 1)","alt":"Manaria Friends â 01 (frame 1)","nro":27,"url":"images/descale_manaria01.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 1)","attributes":{},"skip":false,"key":"2.6.1"},{"backlink":"encoding/descaling.html#fig2.6.2","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 2)","alt":"Manaria Friends â 01 (frame 2)","nro":28,"url":"images/descale_manaria02.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 2)","attributes":{},"skip":false,"key":"2.6.2"},{"backlink":"encoding/descaling.html#fig2.6.3","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 3)","alt":"Manaria Friends â 01 (frame 3)","nro":29,"url":"images/descale_manaria03.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 3)","attributes":{},"skip":false,"key":"2.6.3"},{"backlink":"encoding/descaling.html#fig2.6.4","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 4)","alt":"Manaria Friends â 01 (frame 4)","nro":30,"url":"images/descale_manaria04.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 4)","attributes":{},"skip":false,"key":"2.6.4"},{"backlink":"encoding/descaling.html#fig2.6.5","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 4 getnative graph)","alt":"Manaria Friends â 01 (frame 4 getnative graph)","nro":31,"url":"images/descale_graph.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 4 getnative graph)","attributes":{},"skip":false,"key":"2.6.5"},{"backlink":"encoding/descaling.html#fig2.6.6","level":"2.6","list_caption":"Figure: Date A Live III â 01 (getnative graph)","alt":"Date A Live III â 01 (getnative graph)","nro":32,"url":"images/descale_native1080_graph.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Date A Live III â 01 (getnative graph)","attributes":{},"skip":false,"key":"2.6.6"},{"backlink":"encoding/descaling.html#fig2.6.7","level":"2.6","list_caption":"Figure: Miru Tights â 02 (getnative graph)","alt":"Miru Tights â 02 (getnative graph)","nro":33,"url":"images/descale_bad_graph1.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Miru Tights â 02 (getnative graph)","attributes":{},"skip":false,"key":"2.6.7"},{"backlink":"encoding/descaling.html#fig2.6.8","level":"2.6","list_caption":"Figure: Black Lagoon (getnative graph)","alt":"Black Lagoon (getnative graph)","nro":34,"url":"images/descale_bad_graph2.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Black Lagoon (getnative graph)","attributes":{},"skip":false,"key":"2.6.8"},{"backlink":"encoding/descaling.html#fig2.6.9","level":"2.6","list_caption":"Figure: Kizumonogatari I","alt":"Kizumonogatari I","nro":35,"url":"images/descale_ararararagi.png","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kizumonogatari I","attributes":{},"skip":false,"key":"2.6.9"},{"backlink":"encoding/descaling.html#fig2.6.10","level":"2.6","list_caption":"Figure: Kizumonogatari I (getnative graph)","alt":"Kizumonogatari I (getnative graph)","nro":36,"url":"images/descale_ararararagi_graph.png","index":10,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kizumonogatari I (getnative graph)","attributes":{},"skip":false,"key":"2.6.10"},{"backlink":"encoding/descaling.html#fig2.6.11","level":"2.6","list_caption":"Figure: Aikatsu Friends! â NCOP (getnative graph)","alt":"Aikatsu Friends! â NCOP (getnative graph)","nro":37,"url":"images/descale_good_graph.png","index":11,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aikatsu Friends! â NCOP (getnative graph)","attributes":{},"skip":false,"key":"2.6.11"},{"backlink":"encoding/descaling.html#fig2.6.12","level":"2.6","list_caption":"Figure: Kaguya-sama: Love Is War â OP (credits mask)","alt":"Kaguya-sama: Love Is War â OP (credits mask)","nro":38,"url":"images/descale_credits_mask.png","index":12,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kaguya-sama: Love Is War â OP (credits mask)","attributes":{},"skip":false,"key":"2.6.12"},{"backlink":"encoding/descaling.html#fig2.6.13","level":"2.6","list_caption":"Figure: Kaguya-sama: Love Is War â OP (descaled)","alt":"Kaguya-sama: Love Is War â OP (descaled)","nro":39,"url":"images/descale_credits.png","index":13,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kaguya-sama: Love Is War â OP (descaled)","attributes":{},"skip":false,"key":"2.6.13"},{"backlink":"encoding/descaling.html#fig2.6.14","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (end card)","alt":"Manaria Friends â 01 (end card)","nro":40,"url":"images/descale_native1080.png","index":14,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (end card)","attributes":{},"skip":false,"key":"2.6.14"},{"backlink":"encoding/descaling.html#fig2.6.15","level":"2.6","list_caption":"Figure: (Don't descale this)","alt":"(Don't descale this)","nro":41,"url":"images/descale_dontdescalethis.png","index":15,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"(Don't descale this)","attributes":{},"skip":false,"key":"2.6.15"},{"backlink":"encoding/descaling.html#fig2.6.16","level":"2.6","list_caption":"Figure: Akanesasu Shoujo â 01 (src)","alt":"Akanesasu Shoujo â 01 (src)","nro":42,"url":"images/descale_akanesasu_src.png","index":16,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Akanesasu Shoujo â 01 (src)","attributes":{},"skip":false,"key":"2.6.16"},{"backlink":"encoding/descaling.html#fig2.6.17","level":"2.6","list_caption":"Figure: Akanesasu Shoujo â 01 (rescaled)","alt":"Akanesasu Shoujo â 01 (rescaled)","nro":43,"url":"images/descale_akanesasu_rescaled.png","index":17,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Akanesasu Shoujo â 01 (rescaled)","attributes":{},"skip":false,"key":"2.6.17"},{"backlink":"encoding/resampling.html#fig2.7.1","level":"2.7","list_caption":"Figure: Bicubic B-C parameters","alt":"Bicubic B-C parameters","nro":44,"url":"images/resample_cubic_survey.gif","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Bicubic B-C parameters","attributes":{},"skip":false,"key":"2.7.1"},{"backlink":"encoding/resampling.html#fig2.7.2","level":"2.7","list_caption":"Figure: Two-dimensional kernel. The radius is colored green.","alt":"Two-dimensional kernel. The radius is colored green.","nro":45,"url":"images/resample_polar.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Two-dimensional kernel. The radius is colored green.","attributes":{},"skip":false,"key":"2.7.2"},{"backlink":"encoding/resampling.html#fig2.7.3","level":"2.7","list_caption":"Figure: A grayscale gradient from 0 to 255.","alt":"A grayscale gradient from 0 to 255.","nro":46,"url":"images/resample_gamma_shades.jpg","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"A grayscale gradient from 0 to 255.","attributes":{},"skip":false,"key":"2.7.3"},{"backlink":"encoding/resampling.html#fig2.7.4","level":"2.7","list_caption":"Figure: YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","alt":"YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","nro":47,"url":"images/resample_chroma_placement.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","attributes":{},"skip":false,"key":"2.7.4"},{"backlink":"encoding/resampling.html#fig2.7.5","level":"2.7","list_caption":"Figure: Pixel mapping in common resampling algorithms (2 -> 4 upscale).","alt":"Pixel mapping in common resampling algorithms (2 -> 4 upscale).","nro":48,"url":"images/resample_matchedges.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Pixel mapping in common resampling algorithms (2 -> 4 upscale).","attributes":{},"skip":false,"key":"2.7.5"},{"backlink":"typesetting/aegisub.html#fig3.1.1","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 1","alt":"Aegisub 8975-master-8d77da3 preferences 1","nro":49,"url":"images/preferences-1.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 1","attributes":{},"skip":false,"key":"3.1.1"},{"backlink":"typesetting/aegisub.html#fig3.1.2","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 2","alt":"Aegisub 8975-master-8d77da3 preferences 2","nro":50,"url":"images/preferences-2.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 2","attributes":{},"skip":false,"key":"3.1.2"},{"backlink":"typesetting/aegisub.html#fig3.1.3","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 3","alt":"Aegisub 8975-master-8d77da3 preferences 3","nro":51,"url":"images/preferences-3.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 3","attributes":{},"skip":false,"key":"3.1.3"},{"backlink":"typesetting/aegisub.html#fig3.1.4","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 script properties 1","alt":"Aegisub 8975-master-8d77da3 script properties 1","nro":52,"url":"images/script_properties-1.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 script properties 1","attributes":{},"skip":false,"key":"3.1.4"}]},"gitbook":"*"},"file":{"path":"encoding/masking-limiting-etc.md","mtime":"2019-10-03T23:55:38.122Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-03T23:56:44.150Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/clipboard.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/initclip.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

