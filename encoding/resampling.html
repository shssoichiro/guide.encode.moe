
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Resampling Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-image-captions/image-captions.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-term/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="../styles/website.css">
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="video-encoding.html" />
    
    
    <link rel="prev" href="descaling.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Overview</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../CONTRIBUTING.html">
            
                <a href="../CONTRIBUTING.html">
            
                    
                    Contributing to the Guide
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../overview/preface.html">
            
                <a href="../overview/preface.html">
            
                    
                    Preface
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../overview/roles.html">
            
                <a href="../overview/roles.html">
            
                    
                    Roles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../overview/requirements.html">
            
                <a href="../overview/requirements.html">
            
                    
                    Requirements
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Encoding</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="preparation.html">
            
                <a href="preparation.html">
            
                    
                    Preparations and Necessary Software
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="basics-and-workflow.html">
            
                <a href="basics-and-workflow.html">
            
                    
                    Basics and General Workflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="video-artifacts.html">
            
                <a href="video-artifacts.html">
            
                    
                    Recognizing Video Artifacts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="scenefiltering.html">
            
                <a href="scenefiltering.html">
            
                    
                    Scenefiltering
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="masking-limiting-etc.html">
            
                <a href="masking-limiting-etc.html">
            
                    
                    Masking, Limiting, and Related Functions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="descaling.html">
            
                <a href="descaling.html">
            
                    
                    Descaling
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="2.7" data-path="resampling.html">
            
                <a href="resampling.html">
            
                    
                    Resampling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="video-encoding.html">
            
                <a href="video-encoding.html">
            
                    
                    Codecs
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Typesetting</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../typesetting/aegisub.html">
            
                <a href="../typesetting/aegisub.html">
            
                    
                    Aegisub and Other Tools
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Resources and References</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../archived-websites/bt601-vs-bt709.html">
            
                <a href="../archived-websites/bt601-vs-bt709.html">
            
                    
                    Colorspaces
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Legal</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="../impressum.html">
            
                <a href="../impressum.html">
            
                    
                    Impressum
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="../privacy-policy.html">
            
                <a href="../privacy-policy.html">
            
                    
                    Privacy Policy
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Resampling</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="resampling"><a name="resampling" class="plugin-anchor" href="#resampling"><i class="fa fa-link" aria-hidden="true"></i></a>Resampling</h1>
<p>Resampling is a technique applied in various
image processing tasks,
most prominently scaling/resizing,
but also shifting and rotation.</p>
<h2 id="resizing"><a name="resizing" class="plugin-anchor" href="#resizing"><i class="fa fa-link" aria-hidden="true"></i></a>Resizing</h2>
<p>The most common class of resampling algorithms
used for resizing are the convolution-based resamplers.
As the name suggests,
these work by <a href="https://en.wikipedia.org/wiki/Convolution" target="_blank">convolving</a> the image
with a filter function.
These filter functions,
also known as kernels,
are what the terms Bilinear/Bicubic/Lanczos/etc. generally refer to.
The <a href="https://entropymine.com/imageworsener/resample/" target="_blank">ImageWorsener documentation</a> features a great
visual explanation of how this process works in detail.
It is strongly recommended to read it.
If you wish to explore the mathematics behind the design
of these filters,
the <a href="https://www.pbrt.org/chapters/pbrt_chapter7.pdf" target="_blank">Sampling and Reconstruction chapter</a>
of <a href="https://www.pbrt.org/" target="_blank">Physically Based Rendering</a> is one of the best places
for a layman to start.</p>
<h3 id="filters"><a name="filters" class="plugin-anchor" href="#filters"><i class="fa fa-link" aria-hidden="true"></i></a>Filters</h3>
<p>All resampling kernels behave slightly differently
and generate artifacts of differing kinds and severity.</p>
<p>It should be noted that there is no &#x201C;objectively best&#x201D; resampling filter,
so it is largely a matter of personal preference.
There are no hard and fast rules about
which resampler performs best for any given type of content,
so it&#x2019;s best to test them yourself.</p>
<p>A short overview of the most common filters follows.
For a much more extensive explanation of the different filters,
including details on the exact algorithms,
see <a href="http://www.imagemagick.org/Usage/filter/" target="_blank">ImageMagick&#x2019;s guide</a>.</p>
<p>Additionally,
<a href="https://forum.doom9.org/showthread.php?t=160038" target="_blank">ResampleHQ</a>&apos;s documentation features
an excellent visual comparison of common filter kernels;
a back-up is available <a href="http://maven.whatbox.ca:11665/resample_kernels/kernels.html" target="_blank">here</a>.</p>
<h4 id="box-filter--nearest-neigbour"><a name="box-filter--nearest-neigbour" class="plugin-anchor" href="#box-filter--nearest-neigbour"><i class="fa fa-link" aria-hidden="true"></i></a>Box filter / Nearest Neigbour</h4>
<p>When upscaling,
the Box filter will behave just like
<a href="https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation" target="_blank">Nearest Neighbour (<em>NN</em>) interpolation</a>,
that is,
it will just pick the closest pixel in the input image
for every output pixel.
This results in the source pixel grid being magnified
without any smoothing or merging of adjacent pixels,
providing a faithful representation of the original pixel grid.
This is very useful when inspecting an image up close
to examine the pixel structure,
or when enlarging <a href="https://en.wikipedia.org/wiki/Pixel_art" target="_blank">pixel art</a>,
but not suitable for regular content
due to the jagged lines and deformed details it causes.</p>
<p>When downscaling,
the Box filter behaves differently to
NN&#x2014;which continues to just
pick the closest pixel and
be done with it&#x2014;in that it instead
merges adjacent pixels together.
(This is because generally,
filter kernels are widened
in proportion to the scaling factor
when downscaling,
which, in effect, applies a <a href="https://en.wikipedia.org/wiki/Low-pass_filter" target="_blank">low-pass filter</a>
that serves to prevent aliasing.)
Unlike most other filters, however,
it averages them evenly
instead of giving the central ones more weight.
(For example, reducing a 10 pixel row to 5 pixels
will average every pixel pair.)
This, again,
can be a useful property in specific cases,
but is not generally desirable.</p>
<p>The Box filter is available in VapourSynth
in the <code>fmtconv</code> plug-in:</p>
<pre><code class="lang-py">clip = core.fmtc.resample(src, w, h, kernel=<span class="hljs-string">&quot;box&quot;</span>)
</code></pre>
<p>Nearest Neighbour interpolation is part of the built-in <code>resize</code> plug-in:</p>
<pre><code class="lang-py">clip = core.resize.Point(src, w, h)
</code></pre>
<p>Most <a href="preparation.html#the-editor">script editors</a> including VSEdit feature NN scaling in the preview;
it is recommended to use it over Bilinear
when making filtering decisions.</p>
<h4 id="bilinear--triangle"><a name="bilinear--triangle" class="plugin-anchor" href="#bilinear--triangle"><i class="fa fa-link" aria-hidden="true"></i></a>Bilinear / Triangle</h4>
<p>Bilinear, also known as Triangle due to its graph&#x2019;s shape,
is one of the most common algorithms in widespread use
because of its simplicity and speed.
However,
it generally creates all sorts of nasty artifacts
and is inferior in quality to most other filters.
The only advantage it offers is speed,
so don&#x2019;t use it unless you&#x2019;re sure you have to.</p>
<p>VapourSynth example:</p>
<pre><code class="lang-py">clip = core.resize.Bilinear(src, w, h)
</code></pre>
<h4 id="mitchell-netravali--bicubic"><a name="mitchell-netravali--bicubic" class="plugin-anchor" href="#mitchell-netravali--bicubic"><i class="fa fa-link" aria-hidden="true"></i></a>Mitchell-Netravali / Bicubic</h4>
<p>The Mitchell-Netravali filter,
also known as Bicubic,
is one of the most popular resampling algorithms,
and the default for many image processing programs,
because it is usually considered a good neutral default.</p>
<p>It takes two parameters, B and C,
which can be used to tweak the filter&#x2019;s behaviour.
For upscaling, it is recommended to use values that satisfy the equation
<code>b + 2c = 1</code>.</p>
<p>The graph below outlines
the various kinds of artifacts
different B-C-configurations produce.</p>
<figure id="fig2.7.1"><img src="images/resample_cubic_survey.gif" alt="Bicubic B-C parameters"><figcaption>Image 2.7.1 - Bicubic B-C parameters</figcaption></figure>
<p>Roughly speaking,
raising B will cause blurring
and raising C will cause ringing.</p>
<p>Mitchell-Netravali generalizes all smoothly fitting
(continuous first derivative) piece-wise cubic filters,
so any of them can be expressed with the appropiate parameters.
Below you can find a list of common cubic filters
and their corresponding parameters in Mitchell-Netravali.</p>
<ul>
<li>B-Spline &#x2013; b=1, c=0</li>
<li>Hermite &#x2013; b=0, c=0</li>
<li>Mitchell-Netravali &#x2013; b=1/3, c=1/3 (sometimes referred to as just &#x201C;Mitchell&#x201D;)</li>
<li>Catmull-Rom &#x2013; b=0, c=0.5</li>
<li>Sharp Bicubic &#x2013; b=0, c=1</li>
</ul>
<p>Hermite is often considered one of the best choices for downscaling,
as it produces only minimal artifacting,
at the cost of slight blurriness.</p>
<p>VapourSynth example:</p>
<pre><code class="lang-py"><span class="hljs-comment"># &apos;filter_param_a&apos; and &apos;filter_param_b&apos; refer to B and C, respectively</span>
clip = core.resize.Bicubic(src, w, h, filter_param_a=<span class="hljs-number">0</span>, filter_param_b=<span class="hljs-number">0.5</span>)
</code></pre>
<h4 id="lanczos"><a name="lanczos" class="plugin-anchor" href="#lanczos"><i class="fa fa-link" aria-hidden="true"></i></a>Lanczos</h4>
<p>Lanczos is generally considered
a very high-quality resampler for upscaling,
especially its <a href="#elliptical-weighted-averaging-ewa-cylindrical-polar-circular">EWA version</a>.</p>
<p>It is usually slightly sharper than Mitchell (Bicubic b=c=1/3),
but might produce slightly more ringing.</p>
<p>Lanczos takes an additional parameter
that controls the filter&#x2019;s number of lobes,
or <em>taps</em>.
Increasing the number of lobes
improves sharpness at the cost of increased ringing.
You might occasionally see the tap count
appended to the filter name to clarify
the exact filter used, e.g. Lanczos2 for 2 taps.</p>
<p>For downscaling,
higher tap counts might help in
suppressing <a href="http://www.imagemagick.org/Usage/filter/#aliasing" target="_blank">Moir&#xE9; effects</a>.</p>
<pre><code class="lang-py"><span class="hljs-comment"># &apos;filter_param_a&apos; specifies the tap count</span>
clip = core.resize.Lanczos(src, w, h, filter_param_a=<span class="hljs-number">2</span>)
</code></pre>
<h4 id="spline"><a name="spline" class="plugin-anchor" href="#spline"><i class="fa fa-link" aria-hidden="true"></i></a>Spline</h4>
<p>Spline is another high-quality resizer.</p>
<p>Spline, like Lanczos,
can be finetuned by configuring its number of lobes.
Unlike Lanczos,
however,
Splines with different tap counts are usually split
into seperate functions,
with <code>(tap_count&#x2217;2)^2</code> appended to their name,
e.g. Spline36 for 3 taps, Spline64 for 4, etc.
(This number repesents the total amount of input pixels
involved in the calculation of any given output pixel.)</p>
<p>Spline36 is a very popular choice for downscaling,
since it is fairly artifact-free yet decently sharp.
For upscaling,
it looks similiar to Lanczos3,
though arguably slightly less artifacted.</p>
<p>VS example:</p>
<pre><code class="lang-py">clip = core.resize.Spline36(src, w, h)
</code></pre>
<p>Higher tap counts can be used via fmtconv:</p>
<pre><code class="lang-py">clip = core.fmtc.resample(src, w, h, kernel=<span class="hljs-string">&quot;spline&quot;</span>, taps=<span class="hljs-number">6</span>) <span class="hljs-comment"># equivalent to Spline144</span>
</code></pre>
<h4 id="gauss"><a name="gauss" class="plugin-anchor" href="#gauss"><i class="fa fa-link" aria-hidden="true"></i></a>Gauss</h4>
<p>The Gaussian filter is very special in that its Fourier transform<sup><a href="#fn_1" id="reffn_1">1</a></sup>
is another Gaussian
whose width is inversely proportional to the spatial function&#x2019;s.
This can be harnessed to remove and amplify high frequencies
in a very controllable way.
Widening the filter,
for example,
will confine the output to small frequencies (blurrier),
whereas squashing it will amplify higher frequencies (more aliasing).</p>
<p>In practice,
though,
the Gaussian filter isn&#x2019;t all too useful for regular resizing.
However,
it can be used to accurately emulate a Gaussian blur
(when used without resizing)
in VapourSynth.</p>
<p>For example:</p>
<pre><code class="lang-py">blurred = core.fmtc.resample(src, kernel=<span class="hljs-string">&quot;gauss&quot;</span>, fh=<span class="hljs-number">-1</span>, fv=<span class="hljs-number">-1</span>, a1=<span class="hljs-number">1</span>)
</code></pre>
<p><code>fh=-1, fv=-1</code> forces the processing
when no resizing is performed.
<code>a1</code> controls the blurring:
the higher,
the sharper the image.</p>
<h3 id="interpolation-filters"><a name="interpolation-filters" class="plugin-anchor" href="#interpolation-filters"><i class="fa fa-link" aria-hidden="true"></i></a>Interpolation filters</h3>
<p>Some sources will categorize filters as either
interpolation filters or non-interpolation filters.</p>
<p>Interpolation filters are those that
when applied &#x201C;in-place&#x201D;,
i.e. at the location of the input samples,
don&#x2019;t alter the sample value.
Therefore,
they only interpolate &#x201C;missing&#x201D; values,
leaving the input samples untouched.</p>
<p>This is true for filters that evaluate to 0
at all integer positions except 0
or whose support is &lt;= 1.
Examples include:
(Windowed) Sinc filters,
such as Lanczos,
Bicubic with B=0,
e.g. Hermite and Catmull-Rom,
and Triangle/Bilinear.</p>
<p>This can be a beneficial property in some cases,
for example the No-Op case.
No-Op means that no scaling, shifting or similiar is performed,
that is, the input is resampled at exactly the same positions.
In this case,
an interpolation filter will return the input image untouched,
whereas other filters will slightly alter it.</p>
<p>Another,
more practical,
case where this property is useful
is when shifting an image by full pixel widths (integers),
again because input pixel values aren&#x2019;t changed
but just relocated.</p>
<h3 id="two-dimensional-resampling"><a name="two-dimensional-resampling" class="plugin-anchor" href="#two-dimensional-resampling"><i class="fa fa-link" aria-hidden="true"></i></a>Two-dimensional resampling</h3>
<p>There are two different ways to go about
resampling in two dimensions.</p>
<h4 id="tensor-resampling-orthogonal-2-pass-seperated"><a name="tensor-resampling-orthogonal-2-pass-seperated" class="plugin-anchor" href="#tensor-resampling-orthogonal-2-pass-seperated"><i class="fa fa-link" aria-hidden="true"></i></a>Tensor resampling (<em>orthogonal</em>, <em>2-pass</em>, <em>seperated</em>)</h4>
<p>The image is resampled in two seperate passes:
First it is resampled horizontally, then vertically.
This allows images to be treated 1-dimensionally
since each pixel row/column can be resampled seperately.
The main advantage of this method is that it&apos;s extremly fast,
which is why it&#x2019;s the much more common one;
generally, unless indicated otherwise,
this is what is used.</p>
<h4 id="elliptical-weighted-averaging-ewa-cylindrical-polar-circular"><a name="elliptical-weighted-averaging-ewa-cylindrical-polar-circular" class="plugin-anchor" href="#elliptical-weighted-averaging-ewa-cylindrical-polar-circular"><i class="fa fa-link" aria-hidden="true"></i></a>Elliptical Weighted Averaging (<em>&quot;EWA&quot;</em>, <em>cylindrical</em>, <em>polar</em>, <em>circular</em>)</h4>
<figure id="fig2.7.2"><img src="images/resample_polar.png" alt="Two-dimensional kernel. The radius is colored green."><figcaption>Image 2.7.2 - Two-dimensional kernel. The radius is colored green.</figcaption></figure>
<p>All input samples whose <a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank">Euclidian distance</a> to the pixel
is within the filter&#x2019;s radius contribute to its value.
The Euclidian distance is passed to the filter kernel.
This is a lot more costly than tensor resampling in terms of runtime.</p>
<h3 id="scaling-in-modified-colorspaces"><a name="scaling-in-modified-colorspaces" class="plugin-anchor" href="#scaling-in-modified-colorspaces"><i class="fa fa-link" aria-hidden="true"></i></a>Scaling in modified colorspaces</h3>
<p>The colorspace used when resampling
can significantly impact the output&#x2019;s subjective quality.</p>
<h4 id="downscaling-in-linear-light"><a name="downscaling-in-linear-light" class="plugin-anchor" href="#downscaling-in-linear-light"><i class="fa fa-link" aria-hidden="true"></i></a>Downscaling in linear light</h4>
<p>Downscaling in gamma-corrected light instead of linear light
can sometimes noticeably dim the image.
To see why this happens,
consider this gradient:</p>
<figure id="fig2.7.3"><img src="images/resample_gamma_shades.jpg" alt="A grayscale gradient from 0 to 255."><figcaption>Image 2.7.3 - A grayscale gradient from 0 to 255.</figcaption></figure>
<p>It should be apparent
that the brightness doesn&#x2019;t scale linearly with the pixel values.
This is because most digital video
uses <a href="https://en.wikipedia.org/wiki/Gamma_correction" target="_blank">gamma-transformed</a> pixel values
in order to compress more perceptually distinct color shades
into 8 bit.
This causes the encoded pixel values
to deviate from their expected brightness,
e.g. a grey pixel has value 187 instead of 127 in sRGB.
This poses a problem when merging and interpolating colors,
because the average pixel value of two colors no longer corresponds
to their average perceived brightness.
For example,
if you wanted to merge black and white (0 and 255),
you would expect to get grey,
but since grey actually has a value of ~187,
the output pixel would turn out substantially darker,
if you were you to naively average the pixel values.</p>
<p>To calculate the correct values,
the gamma transform needs to be reversed before scaling
and re-applied afterwards.</p>
<p>The dimming effect of scaling in gamma-corrected light
is usually only noticeable
in dense color patterns,
e.g. small black text on a white background,
stars in the night sky, etc,
and much less so in blurrier areas.</p>
<p>See <a href="https://slowpics.org/comparison/8103b2d1-b9d4-4d7e-b7a7-3197ae999244" target="_blank">this comparison</a> for a particularly extreme example
of linear vs gamma downscaling.</p>
<p>However,
this doesn&#x2019;t necessarily mean downscaling in linear light
is always the right choice,
since it noticeably accentuates dark halos
introduced by scaling.
Thus,
it may be wise to scale in gamma light
when using a resizer prone to overshooting,
like high-lobe Lanczos.
Besides,
the dimming may even be desirable in some cases like black text on white paper,
because it preserves legibility.</p>
<p>If you choose to downscale in linear light,
make sure to use a sufficiently high bitdepth
so as to not introduce banding.</p>
<p>Example code for resizing in linear RGB light:</p>
<pre><code class="lang-py">linear = core.resize.Bicubic(src, format=vs.RGBS, transfer_in_s=<span class="hljs-string">&quot;709&quot;</span>, transfer_s=<span class="hljs-string">&quot;linear&quot;</span>, matrix_in_s=<span class="hljs-string">&quot;709&quot;</span>)
scaled_linear = core.resize.Bicubic(linear, <span class="hljs-number">640</span>, <span class="hljs-number">360</span>)
scaled_gamma = core.resize.Bicubic(scaled_linear, format=src.format, transfer_s=<span class="hljs-string">&quot;709&quot;</span>, transfer_in_s=<span class="hljs-string">&quot;linear&quot;</span>, matrix_s=<span class="hljs-string">&quot;709&quot;</span>)
</code></pre>
<p>Note that the <code>matrix_s</code> and <code>matrix_in_s</code> arguments
are only necessary when <code>src</code> is YUV;
otherwise, they should be omitted.</p>
<h4 id="upscaling-in-sigmoidized-light"><a name="upscaling-in-sigmoidized-light" class="plugin-anchor" href="#upscaling-in-sigmoidized-light"><i class="fa fa-link" aria-hidden="true"></i></a>Upscaling in sigmoidized light</h4>
<p>In order to attenuate both dark and white halos
introduced by upscaling,
you can resize through a sigmoidized colorspace.</p>
<p>This means converting the linear RGB version of an image
to a custom colorspace with an S-shaped intensitiy curve
before scaling and converting it back afterwards.
What this does, essentially,
is decrease the image&#x2019;s contrast
by pushing extreme values of both dark and bright
towards the middle.</p>
<p>Quoting Nicholas Robidoux from ImageMagick:</p>
<blockquote>
<p>You may decrease halos and increase perceptual sharpness by increasing the sigmoidal contrast (up to 11.5, say).</p>
<p>Higher contrasts are especially recommended with greyscale images (even &quot;false RGB greyscale&quot; that have three proportional color channels).</p>
<p>The downside of sigmoidization is that it sometimes produces &quot;color bleed&quot; artefacts that look a bit like cheap flexographic (&quot;gummidruck&quot;) printing or chromatic aberration.</p>
<p>In addition, sigmoidization&apos;s &quot;fattening&quot; of extreme light and dark values may not work for your image content.</p>
<p>If such artefacts are obvious, push the contrast value down from 7.5 (to 5, for example, or even lower).</p>
<p>Setting the contrast to 0 is equivalent to enlarging through linear RGB.</p>
</blockquote>
<p>(Robidoux, 2012)<sup><a href="#fn_2" id="reffn_2">2</a></sup></p>
<p>Example code for VS:</p>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> havsfunc <span class="hljs-keyword">as</span> hf
linear = core.resize.Bicubic(src, format=vs.RGBS, transfer_in_s=<span class="hljs-string">&quot;709&quot;</span>, transfer_s=<span class="hljs-string">&quot;linear&quot;</span>, matrix_in_s=<span class="hljs-string">&quot;709&quot;</span>)
sigmoidized = hf.SigmoidInverse(linear, thr=<span class="hljs-number">0.5</span>, cont=<span class="hljs-number">6.5</span>) <span class="hljs-comment"># &apos;cont&apos; corresponds to the &#x201C;sigmoidal contrast&#x201D; mentioned above</span>
scaled_sigmoid = core.resize.Bicubic(sigmoidized, <span class="hljs-number">640</span>, <span class="hljs-number">360</span>)
de_sigmoidized = hf.SigmoidDirect(scaled_sigmoid, thr=<span class="hljs-number">0.5</span>, cont=<span class="hljs-number">6.5</span>)
scaled_gamma = core.resize.Bicubic(de_sigmoidized, format=src.format, transfer_s=<span class="hljs-string">&quot;709&quot;</span>, transfer_in_s=<span class="hljs-string">&quot;linear&quot;</span>, matrix_s=<span class="hljs-string">&quot;709&quot;</span>)
</code></pre>
<h3 id="neural-network-scalers"><a name="neural-network-scalers" class="plugin-anchor" href="#neural-network-scalers"><i class="fa fa-link" aria-hidden="true"></i></a>Neural network scalers</h3>
<p>NN-based scalers have become
increasingly popular in recent times.
This is because
they aren&#x2019;t subject to the technical limitations
of convolution-based resamplers&#x2014;which beyond a certain point
only trade one artifact for another&#x2014;and thus produce
much higher quality upscales.</p>
<h5 id="nnedi3"><a name="nnedi3" class="plugin-anchor" href="#nnedi3"><i class="fa fa-link" aria-hidden="true"></i></a>NNEDI3</h5>
<p>This is the current de-facto standard
for high-quality upscaling
because it generally produces equally as sharp or sharper
images than conventional scalers,
while avoiding any major artifacting
such as haloing, ringing or aliasing.</p>
<p>Nnedi3 was originally conceived as a deinterlacer;
as such,
it only doubles a frame&#x2019;s height,
leaving the original pixel rows untouched
and interpolating the missing ones.
This, however, can trivially be leveraged
to increase image dimensions by powers of two
(by doubling <em>n</em> times,
flipping the image,
doubling <em>n</em> times again,
and flipping back).</p>
<p>Upsampling to arbitrary dimensions can be achieved
by scaling by the smallest power of two
that results in a bigger image than desired,
and downscaling to the requested resolution
with a conventional scaler
(the most popular choice for this is <a href="#spline">Spline36</a>).</p>
<p>However,
you should note that
good quality comes at a cost:
nnedi3 will generally be several orders of magnitude
slower than conventional resamplers.</p>
<p>VapourSynth usage example:</p>
<pre><code class="lang-py"><span class="hljs-keyword">from</span> nnedi3_rpow2 <span class="hljs-keyword">import</span> *
<span class="hljs-comment"># &apos;spline36&apos; here is technically redundant since it&#x2019;s the default</span>
up = nnedi3_rpow2(src, width=<span class="hljs-number">1920</span>, height=<span class="hljs-number">1080</span>, kernel=<span class="hljs-string">&quot;spline36&quot;</span>)
</code></pre>
<h2 id="shifting"><a name="shifting" class="plugin-anchor" href="#shifting"><i class="fa fa-link" aria-hidden="true"></i></a>Shifting</h2>
<p>Shifting an image by an arbitrary amount,
including non-integer values,
requires resampling as well.
For example,
left-shifting by a quarter pixel
will resample the image at the input samples&#x2019; positions minus 0.25.<sup><a href="#fn_3" id="reffn_3">3</a></sup>
This also means that,
unless a <a href="#interpolation-filters">interpolative filter</a> is used,
even shifting by integer amounts will alter the image.</p>
<p>Side note:
It can be interesting to think of shifting
not as resampling at shifted pixel locations,
but as resampling at the input locations
with a shifted kernel.</p>
<h3 id="chroma-shifting"><a name="chroma-shifting" class="plugin-anchor" href="#chroma-shifting"><i class="fa fa-link" aria-hidden="true"></i></a>Chroma shifting</h3>
<p>When going from 4:2:0 <a href="https://en.wikipedia.org/wiki/Chroma_subsampling" target="_blank">subsampling</a>
to 4:4:4 (no subsampling),
it is important to take into account chroma placement
and to shift the chroma accordingly
to ensure it aligns with the luma.</p>
<figure id="fig2.7.4"><img src="images/resample_chroma_placement.png" alt="YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right)."><figcaption>Image 2.7.4 - YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).</figcaption></figure>
<p>There are two commonly used
chroma siting patterns,
as illustrated by the graphic above.
Most digital video today
uses the MPEG-2 variant,
that is,
left-aligned chroma.
This is essential to keep in mind
when going from 4:2:0 to 4:4:4,
because if the chroma planes
are naively upscaled and joined with the luma plane without any shifting,
the chroma will be shifted by a quarter pixel.
This is a consequence of the way
output pixels are usually mapped onto the input grid
during resampling:</p>
<figure id="fig2.7.5"><img src="images/resample_matchedges.png" alt="Pixel mapping in common resampling algorithms (2 -&gt; 4 upscale)."><figcaption>Image 2.7.5 - Pixel mapping in common resampling algorithms (2 -&gt; 4 upscale).</figcaption></figure>
<p>Essentially,
the output grid is scaled
such that the outer edges of the pixel boxes align,
importantly under the assumption that samples are center-aligned
within the pixel boxes.
Therefore,
when scaling a chroma plane by 200%,
which is what happens to the chroma
when going from 4:2:0 to 4:4:4,
the new chroma sample positions will
match up with the luma sample positions.
This would be the correct mapping
if the resamplers&#x2019;s assumption of center-alignment was true&#x2014;if it isn&#x2019;t
(like with MPEG-2 chroma placement)
we have to compensate for the offset by shifting the input samples
by a quarter pixel width to the left
before calculating the output samples.
This way,
the left-alignment is restored.</p>
<p>Similiarly,
when resizing left-aligned 4:2:0 material
while keeping the subsampling,
a slight shift needs to be applied
to preserve the alignment.
Specifically,
the chroma needs to be shifted by
<code>0.25 - 0.25 * src_width/dst_width</code>.<sup><a href="#fn_4" id="reffn_4">4</a></sup></p>
<p>Chroma shifting is performed
automatically under the hood by most format conversion software
(including zimg, VapourSynth&#x2019;s resizing library)
and media players.
Thus, we only need to take care of it
if we handle the chroma upscaling seperately by hand.</p>
<p>In VS,
shifting can be performed with the <code>resize</code> functions&#x2019; <code>src_left</code> parameter:</p>
<pre><code class="lang-py">u = core.std.ShufflePlanes(src, planes=<span class="hljs-number">1</span>, colorfamily=vs.GRAY)
shifted_scaled_u = core.resize.Spline16(u, <span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>, src_left=<span class="hljs-number">0.25</span>) <span class="hljs-comment"># shifts the image to the left by 0.25 pixels</span>
</code></pre>
<hr>
<blockquote id="fn_1">
<sup>1</sup>. The Fourier transform is an ubiqitous concept in image processing, so we strongly advise becoming familiar with at least the basics. A very good resource for this topic is <a href="http://www.fmwconcepts.com/imagemagick/fourier_transforms/fourier.html" target="_blank">ImageMagick&#x2019;s guide</a>.<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#x21A9;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. Robidoux, N. (2012, October 21). Resampling &#x2014; ImageMagick v6 Examples. Retrieved August 22, 2019, from <a href="https://www.imagemagick.org/Usage/filter/nicolas/#upsampling" target="_blank">https://www.imagemagick.org/Usage/filter/nicolas/#upsampling</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#x21A9;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. If you don&#x2019;t understand what this means, read the resources linked above in the <a href="#resizing">resizing section</a>.<a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#x21A9;</a>
</blockquote>
<blockquote id="fn_4">
<sup>4</sup>. This is derived as follows: The shift is the distance between the position of the first luma sample and the position of the first chroma sample (both mapped onto the input grid and given in terms of input chroma pixel widths). The former is located at <code>0.25 + (src_width/dst_width)/4</code>, the latter at <code>(src_width/dst_width)/2</code>. This yields <code>0.25 + (src_width/dst_width)/4 - (src_width/dst_width)/2 = 0.25 + (src_width/dst_width) * (1/4 - 1/2) = 0.25 + (src_width/dst_width) * -0.25</code> for the shift.<a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#x21A9;</a>
</blockquote>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="descaling.html" class="navigation navigation-prev " aria-label="Previous page: Descaling">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="video-encoding.html" class="navigation navigation-next " aria-label="Next page: Codecs">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Resampling","level":"2.7","depth":1,"next":{"title":"Codecs","level":"2.8","depth":1,"path":"encoding/video-encoding.md","ref":"encoding/video-encoding.md","articles":[]},"previous":{"title":"Descaling","level":"2.6","depth":1,"path":"encoding/descaling.md","ref":"encoding/descaling.md","articles":[]},"dir":"ltr"},"config":{"plugin_comments":{"anchors":"adds anchors (and links) to headings","code":"adds line numbers and copy buttons","edit-link":"link to edit page on github in top bar","image-captions":"turns images into figures","term":"{% term %} blocks with different highlighting and copy buttons per command, not whole output"},"plugins":["anchors","code","edit-link","image-captions","term"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"search":{},"term":{"copyButtons":true,"fade":false,"lineStyles":true,"prompt":"(?<prompt>[^\\$^#^:]*)(?<pathsep>:?)(?<path>[^\\$^#]*?)(?<delimiter>[\\$#] )(?<command>.*)$","style":"default"},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"edit-link":{"label":"Edit This Page","base":"https://github.com/Irrational-Encoding-Wizardry/guide.encode.moe/edit/master/"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{},"image-captions":{"caption":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","variable_name":"_pictures"}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{"_pictures":[{"backlink":"overview/roles.html#fig1.4.1","level":"1.4","list_caption":"Figure: [DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","alt":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","nro":1,"url":"images/cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.55].jpg","attributes":{},"skip":false,"key":"1.4.1"},{"backlink":"overview/roles.html#fig1.4.2","level":"1.4","list_caption":"Figure: [DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","alt":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","nro":2,"url":"images/cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"[DameDesuYo] Eromanga-sensei - 01 (1920x1080 10bit AAC) [05CB518E].mkv_snapshot_03.11_[2017.08.18_21.14.43].jpg","attributes":{},"skip":false,"key":"1.4.2"},{"backlink":"encoding/preparation.html#fig2.1.1","level":"2.1","list_caption":"Figure: The main window of VSEdit.","alt":"The main window of VSEdit.","nro":3,"url":"images/cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"The main window of VSEdit.","attributes":{},"skip":false,"key":"2.1.1"},{"backlink":"encoding/preparation.html#fig2.1.2","level":"2.1","list_caption":"Figure: A Jupyter Notebook.","alt":"A Jupyter Notebook.","nro":4,"url":"images/cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"A Jupyter Notebook.","attributes":{},"skip":false,"key":"2.1.2"},{"backlink":"encoding/preparation.html#fig2.1.3","level":"2.1","list_caption":"Figure: VS Multi-Viewerâs editing window.","alt":"VS Multi-Viewerâs editing window.","nro":5,"url":"images/VS-Multi-Viewer_Preview.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"VS Multi-Viewerâs editing window.","attributes":{},"skip":false,"key":"2.1.3"},{"backlink":"encoding/preparation.html#fig2.1.4","level":"2.1","list_caption":"Figure: VS Multi-Viewerâs preview window.","alt":"VS Multi-Viewerâs preview window.","nro":6,"url":"images/VS-Multi-Viewer_Editor.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"VS Multi-Viewerâs preview window.","attributes":{},"skip":false,"key":"2.1.4"},{"backlink":"encoding/video-artifacts.html#fig2.3.1","level":"2.3","list_caption":"Figure: Rakudai-Kishi-no-Cavalry-ep.01.png","alt":"Rakudai-Kishi-no-Cavalry-ep.01.png","nro":7,"url":"images/3cnvimage100.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Rakudai-Kishi-no-Cavalry-ep.01.png","attributes":{},"skip":false,"key":"2.3.1"},{"backlink":"encoding/video-artifacts.html#fig2.3.2","level":"2.3","list_caption":"Figure: Have I been staring at my monitor for too long?","alt":"Have I been staring at my monitor for too long?","nro":8,"url":"images/3cnvimage101.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Have I been staring at my monitor for too long?","attributes":{},"skip":false,"key":"2.3.2"},{"backlink":"encoding/video-artifacts.html#fig2.3.3","level":"2.3","list_caption":"Figure: notevenonce.jpg","alt":"notevenonce.jpg","nro":9,"url":"images/3cnvimage102.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"notevenonce.jpg","attributes":{},"skip":false,"key":"2.3.3"},{"backlink":"encoding/video-artifacts.html#fig2.3.4","level":"2.3","list_caption":"Figure: Blocky Compression","alt":"Blocky Compression","nro":10,"url":"images/blocky2.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Blocky Compression","attributes":{},"skip":false,"key":"2.3.4"},{"backlink":"encoding/video-artifacts.html#fig2.3.5","level":"2.3","list_caption":"Figure: Blocky Exaggeration","alt":"Blocky Exaggeration","nro":11,"url":"images/blocky1.jpg","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Blocky Exaggeration","attributes":{},"skip":false,"key":"2.3.5"},{"backlink":"encoding/video-artifacts.html#fig2.3.6","level":"2.3","list_caption":"Figure: Example image for banding","alt":"Example image for banding","nro":12,"url":"images/banding.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example image for banding","attributes":{},"skip":false,"key":"2.3.6"},{"backlink":"encoding/video-artifacts.html#fig2.3.7","level":"2.3","list_caption":"Figure: Mosquito Noise","alt":"Mosquito Noise","nro":13,"url":"images/mosquito1.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Mosquito Noise","attributes":{},"skip":false,"key":"2.3.7"},{"backlink":"encoding/video-artifacts.html#fig2.3.8","level":"2.3","list_caption":"Figure: field-noise.jpg","alt":"field-noise.jpg","nro":14,"url":"images/3cnvimage103.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"field-noise.jpg","attributes":{},"skip":false,"key":"2.3.8"},{"backlink":"encoding/video-artifacts.html#fig2.3.9","level":"2.3","list_caption":"Figure: Example of underflow (click for comparison)","alt":"Example of underflow (click for comparison)","nro":15,"url":"images/underflow.jpg","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example of underflow (click for comparison)","attributes":{},"skip":false,"key":"2.3.9"},{"backlink":"encoding/video-artifacts.html#fig2.3.10","level":"2.3","list_caption":"Figure: Example of overflow (click for comparison)","alt":"Example of overflow (click for comparison)","nro":16,"url":"images/overflow.jpg","index":10,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Example of overflow (click for comparison)","attributes":{},"skip":false,"key":"2.3.10"},{"backlink":"encoding/video-artifacts.html#fig2.3.11","level":"2.3","list_caption":"Figure: When you see a histogram like this, increase precision.","alt":"When you see a histogram like this, increase precision.","nro":17,"url":"images/overflow_notice.jpg","index":11,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"When you see a histogram like this, increase precision.","attributes":{},"skip":false,"key":"2.3.11"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.1","level":"2.5","list_caption":"Figure: Illustration of the 3x3 neighborhood","alt":"Illustration of the 3x3 neighborhood","nro":18,"url":"images/3x3.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Illustration of the 3x3 neighborhood","attributes":{},"skip":false,"key":"2.5.1"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.2","level":"2.5","list_caption":"Figure: Screenshot of the source.","alt":"Screenshot of the source.","nro":19,"url":"images/halos.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Screenshot of the source.","attributes":{},"skip":false,"key":"2.5.2"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.3","level":"2.5","list_caption":"Figure: Point-enlargement of the halo area.","alt":"Point-enlargement of the halo area.","nro":20,"url":"images/src0.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Point-enlargement of the halo area.","attributes":{},"skip":false,"key":"2.5.3"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.4","level":"2.5","list_caption":"Figure: luma","alt":"luma","nro":21,"url":"images/luma0.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"luma","attributes":{},"skip":false,"key":"2.5.4"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.5","level":"2.5","list_caption":"Figure: mask_outer","alt":"mask_outer","nro":22,"url":"images/mask_outer0.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"mask_outer","attributes":{},"skip":false,"key":"2.5.5"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.6","level":"2.5","list_caption":"Figure: mask_inner","alt":"mask_inner","nro":23,"url":"images/mask_inner0.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"mask_inner","attributes":{},"skip":false,"key":"2.5.6"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.7","level":"2.5","list_caption":"Figure: halos","alt":"halos","nro":24,"url":"images/halos0.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"halos","attributes":{},"skip":false,"key":"2.5.7"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.8","level":"2.5","list_caption":"Figure: dehalo","alt":"dehalo","nro":25,"url":"images/dh0.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"dehalo","attributes":{},"skip":false,"key":"2.5.8"},{"backlink":"encoding/masking-limiting-etc.html#fig2.5.9","level":"2.5","list_caption":"Figure: masked_dehalo","alt":"masked_dehalo","nro":26,"url":"images/dehalod0.png","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"masked_dehalo","attributes":{},"skip":false,"key":"2.5.9"},{"backlink":"encoding/descaling.html#fig2.6.1","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 1)","alt":"Manaria Friends â 01 (frame 1)","nro":27,"url":"images/descale_manaria01.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 1)","attributes":{},"skip":false,"key":"2.6.1"},{"backlink":"encoding/descaling.html#fig2.6.2","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 2)","alt":"Manaria Friends â 01 (frame 2)","nro":28,"url":"images/descale_manaria02.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 2)","attributes":{},"skip":false,"key":"2.6.2"},{"backlink":"encoding/descaling.html#fig2.6.3","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 3)","alt":"Manaria Friends â 01 (frame 3)","nro":29,"url":"images/descale_manaria03.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 3)","attributes":{},"skip":false,"key":"2.6.3"},{"backlink":"encoding/descaling.html#fig2.6.4","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 4)","alt":"Manaria Friends â 01 (frame 4)","nro":30,"url":"images/descale_manaria04.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 4)","attributes":{},"skip":false,"key":"2.6.4"},{"backlink":"encoding/descaling.html#fig2.6.5","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (frame 4 getnative graph)","alt":"Manaria Friends â 01 (frame 4 getnative graph)","nro":31,"url":"images/descale_graph.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (frame 4 getnative graph)","attributes":{},"skip":false,"key":"2.6.5"},{"backlink":"encoding/descaling.html#fig2.6.6","level":"2.6","list_caption":"Figure: Date A Live III â 01 (getnative graph)","alt":"Date A Live III â 01 (getnative graph)","nro":32,"url":"images/descale_native1080_graph.png","index":6,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Date A Live III â 01 (getnative graph)","attributes":{},"skip":false,"key":"2.6.6"},{"backlink":"encoding/descaling.html#fig2.6.7","level":"2.6","list_caption":"Figure: Miru Tights â 02 (getnative graph)","alt":"Miru Tights â 02 (getnative graph)","nro":33,"url":"images/descale_bad_graph1.png","index":7,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Miru Tights â 02 (getnative graph)","attributes":{},"skip":false,"key":"2.6.7"},{"backlink":"encoding/descaling.html#fig2.6.8","level":"2.6","list_caption":"Figure: Black Lagoon (getnative graph)","alt":"Black Lagoon (getnative graph)","nro":34,"url":"images/descale_bad_graph2.png","index":8,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Black Lagoon (getnative graph)","attributes":{},"skip":false,"key":"2.6.8"},{"backlink":"encoding/descaling.html#fig2.6.9","level":"2.6","list_caption":"Figure: Kizumonogatari I","alt":"Kizumonogatari I","nro":35,"url":"images/descale_ararararagi.png","index":9,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kizumonogatari I","attributes":{},"skip":false,"key":"2.6.9"},{"backlink":"encoding/descaling.html#fig2.6.10","level":"2.6","list_caption":"Figure: Kizumonogatari I (getnative graph)","alt":"Kizumonogatari I (getnative graph)","nro":36,"url":"images/descale_ararararagi_graph.png","index":10,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kizumonogatari I (getnative graph)","attributes":{},"skip":false,"key":"2.6.10"},{"backlink":"encoding/descaling.html#fig2.6.11","level":"2.6","list_caption":"Figure: Aikatsu Friends! â NCOP (getnative graph)","alt":"Aikatsu Friends! â NCOP (getnative graph)","nro":37,"url":"images/descale_good_graph.png","index":11,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aikatsu Friends! â NCOP (getnative graph)","attributes":{},"skip":false,"key":"2.6.11"},{"backlink":"encoding/descaling.html#fig2.6.12","level":"2.6","list_caption":"Figure: Kaguya-sama: Love Is War â OP (credits mask)","alt":"Kaguya-sama: Love Is War â OP (credits mask)","nro":38,"url":"images/descale_credits_mask.png","index":12,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kaguya-sama: Love Is War â OP (credits mask)","attributes":{},"skip":false,"key":"2.6.12"},{"backlink":"encoding/descaling.html#fig2.6.13","level":"2.6","list_caption":"Figure: Kaguya-sama: Love Is War â OP (descaled)","alt":"Kaguya-sama: Love Is War â OP (descaled)","nro":39,"url":"images/descale_credits.png","index":13,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Kaguya-sama: Love Is War â OP (descaled)","attributes":{},"skip":false,"key":"2.6.13"},{"backlink":"encoding/descaling.html#fig2.6.14","level":"2.6","list_caption":"Figure: Manaria Friends â 01 (end card)","alt":"Manaria Friends â 01 (end card)","nro":40,"url":"images/descale_native1080.png","index":14,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Manaria Friends â 01 (end card)","attributes":{},"skip":false,"key":"2.6.14"},{"backlink":"encoding/descaling.html#fig2.6.15","level":"2.6","list_caption":"Figure: (Don't descale this)","alt":"(Don't descale this)","nro":41,"url":"images/descale_dontdescalethis.png","index":15,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"(Don't descale this)","attributes":{},"skip":false,"key":"2.6.15"},{"backlink":"encoding/descaling.html#fig2.6.16","level":"2.6","list_caption":"Figure: Akanesasu Shoujo â 01 (src)","alt":"Akanesasu Shoujo â 01 (src)","nro":42,"url":"images/descale_akanesasu_src.png","index":16,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Akanesasu Shoujo â 01 (src)","attributes":{},"skip":false,"key":"2.6.16"},{"backlink":"encoding/descaling.html#fig2.6.17","level":"2.6","list_caption":"Figure: Akanesasu Shoujo â 01 (rescaled)","alt":"Akanesasu Shoujo â 01 (rescaled)","nro":43,"url":"images/descale_akanesasu_rescaled.png","index":17,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Akanesasu Shoujo â 01 (rescaled)","attributes":{},"skip":false,"key":"2.6.17"},{"backlink":"encoding/resampling.html#fig2.7.1","level":"2.7","list_caption":"Figure: Bicubic B-C parameters","alt":"Bicubic B-C parameters","nro":44,"url":"images/resample_cubic_survey.gif","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Bicubic B-C parameters","attributes":{},"skip":false,"key":"2.7.1"},{"backlink":"encoding/resampling.html#fig2.7.2","level":"2.7","list_caption":"Figure: Two-dimensional kernel. The radius is colored green.","alt":"Two-dimensional kernel. The radius is colored green.","nro":45,"url":"images/resample_polar.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Two-dimensional kernel. The radius is colored green.","attributes":{},"skip":false,"key":"2.7.2"},{"backlink":"encoding/resampling.html#fig2.7.3","level":"2.7","list_caption":"Figure: A grayscale gradient from 0 to 255.","alt":"A grayscale gradient from 0 to 255.","nro":46,"url":"images/resample_gamma_shades.jpg","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"A grayscale gradient from 0 to 255.","attributes":{},"skip":false,"key":"2.7.3"},{"backlink":"encoding/resampling.html#fig2.7.4","level":"2.7","list_caption":"Figure: YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","alt":"YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","nro":47,"url":"images/resample_chroma_placement.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"YUV 4:2:0 subsampling with center-aligned chroma (left) and, as per MPEG-2, left-aligned chroma (right).","attributes":{},"skip":false,"key":"2.7.4"},{"backlink":"encoding/resampling.html#fig2.7.5","level":"2.7","list_caption":"Figure: Pixel mapping in common resampling algorithms (2 -> 4 upscale).","alt":"Pixel mapping in common resampling algorithms (2 -> 4 upscale).","nro":48,"url":"images/resample_matchedges.png","index":5,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Pixel mapping in common resampling algorithms (2 -> 4 upscale).","attributes":{},"skip":false,"key":"2.7.5"},{"backlink":"typesetting/aegisub.html#fig3.1.1","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 1","alt":"Aegisub 8975-master-8d77da3 preferences 1","nro":49,"url":"images/preferences-1.png","index":1,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 1","attributes":{},"skip":false,"key":"3.1.1"},{"backlink":"typesetting/aegisub.html#fig3.1.2","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 2","alt":"Aegisub 8975-master-8d77da3 preferences 2","nro":50,"url":"images/preferences-2.png","index":2,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 2","attributes":{},"skip":false,"key":"3.1.2"},{"backlink":"typesetting/aegisub.html#fig3.1.3","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 preferences 3","alt":"Aegisub 8975-master-8d77da3 preferences 3","nro":51,"url":"images/preferences-3.png","index":3,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 preferences 3","attributes":{},"skip":false,"key":"3.1.3"},{"backlink":"typesetting/aegisub.html#fig3.1.4","level":"3.1","list_caption":"Figure: Aegisub 8975-master-8d77da3 script properties 1","alt":"Aegisub 8975-master-8d77da3 script properties 1","nro":52,"url":"images/script_properties-1.png","index":4,"caption_template":"Image _PAGE_LEVEL_._PAGE_IMAGE_NUMBER_ - _CAPTION_","label":"Aegisub 8975-master-8d77da3 script properties 1","attributes":{},"skip":false,"key":"3.1.4"}]},"gitbook":"*"},"file":{"path":"encoding/resampling.md","mtime":"2019-10-03T23:55:38.122Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-03T23:56:44.150Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/clipboard.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/initclip.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-term/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

